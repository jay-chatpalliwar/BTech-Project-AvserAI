{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import urllib\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "import time\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapping from GlassDoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting information: Message: Unable to locate element: .JobCard_salaryEstimate__arV5J; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n",
      "\n",
      "Error extracting information: Message: Unable to locate element: .JobCard_salaryEstimate__arV5J; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n",
      "\n",
      "Error extracting information: Message: Unable to locate element: .JobCard_salaryEstimate__arV5J; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n",
      "\n",
      "Error extracting information: Message: Unable to locate element: .JobCard_salaryEstimate__arV5J; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n",
      "\n",
      "Error extracting information: Message: Unable to locate element: .JobCard_salaryEstimate__arV5J; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n",
      "\n",
      "Error extracting information: Message: Unable to locate element: .JobCard_salaryEstimate__arV5J; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n",
      "\n",
      "Error extracting information: Message: Unable to locate element: .JobCard_salaryEstimate__arV5J; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n",
      "\n",
      "Error extracting information: Message: Unable to locate element: .JobCard_jobTitle___7I6y; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n",
      "\n",
      "Job listings saved to job_listings.json\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "# Setup Firefox options\n",
    "firefox_options = webdriver.FirefoxOptions()\n",
    "firefox_options.add_argument(\"--headless\")  # Run in headless mode (without a GUI)\n",
    "firefox_options.add_argument(\"--no-sandbox\")\n",
    "firefox_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Start the WebDriver\n",
    "driver = webdriver.Firefox(service=Service(GeckoDriverManager().install()), options=firefox_options)\n",
    "\n",
    "# URL of the job listings page\n",
    "# url = \"https://www.glassdoor.co.in/Job/jobs.htm?suggestCount=0&suggestChosen=true&clickSource=searchBtn&typedKeyword=it&sc.keyword=software%20developer%20intern&locT=C&locId=4477468&jobType=fulltime&fromAge=1&radius=6&cityId=-1&minRating=0.0&industryId=-1&sgocId=-1&companyId=-1&employerSizes=0&applicationType=0&remoteWorkType=0\"  # Replace with the actual URL\n",
    "# url = \"https://www.glassdoor.co.in/Job/pune-india-data-analyst-jobs-SRCH_IL.0,10_IC2856202_KO11,23.htm\"  # Replace with the actual URL\n",
    "url = \"https://www.glassdoor.co.in/Job/india-web-developer-jobs-SRCH_IL.0,5_IN115_KO6,19.htm?locId=115&locT=N&sc.keyword=Web%20Developer\"  # Replace with the actual URL\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(10)\n",
    "\n",
    "# Locate the job listing elements\n",
    "job_listings = driver.find_elements(By.CLASS_NAME, \"JobsList_jobListItem__wjTHv\")\n",
    "job_data=[]\n",
    "count = 0\n",
    "for job in job_listings:\n",
    "    \n",
    "    if count > 50:\n",
    "        break\n",
    "    try:\n",
    "        # Extract job title\n",
    "        title_element = job.find_element(By.CLASS_NAME, \"JobCard_jobTitle___7I6y\")\n",
    "        job_title = title_element.text\n",
    "        job_link = title_element.get_attribute(\"href\")  # Get the link to the job\n",
    "        \n",
    "        # Extract employer name\n",
    "        employer_element = job.find_element(By.CLASS_NAME, \"EmployerProfile_compactEmployerName__LE242\")\n",
    "        employer_name = employer_element.text\n",
    "        \n",
    "        # Extract location\n",
    "        location_element = job.find_element(By.CLASS_NAME, \"JobCard_location__rCz3x\")\n",
    "        job_location = location_element.text\n",
    "        \n",
    "        # Extract salary\n",
    "        salary_element = job.find_element(By.CLASS_NAME, \"JobCard_salaryEstimate__arV5J\")\n",
    "        job_salary = salary_element.text\n",
    "        \n",
    "        job_data.append({\n",
    "            \"Position\": job_title,\n",
    "            \"Company\": employer_name,\n",
    "            \"Location\": job_location,\n",
    "            \"Salary\": job_salary,\n",
    "            \"url\": job_link\n",
    "        })\n",
    "        count += 1\n",
    "        # print(\"Salary:\",job_salary)\n",
    "    except Exception as e:\n",
    "        print(\"Error extracting information:\", e)\n",
    "\n",
    "with open('job_listings.json', 'w') as json_file:\n",
    "    json.dump(job_data, json_file, indent=4)\n",
    "\n",
    "print(\"Job listings saved to job_listings.json\")\n",
    "print(len(job_listings))\n",
    "# Close the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def summarize_job_description(job_text):\n",
    "    # Extracting responsibilities using keywords commonly associated with duties\n",
    "    responsibilities = re.findall(r\"(?:Design|Integrate|Identify|Help|Translate|Ensure|Build|Work|Debug|Customise|Demonstrate|Carry)\\b.*\", job_text)\n",
    "    \n",
    "    # Extracting tech stack keywords\n",
    "    tech_stack_match = re.search(r\"Proficient in \\{\\{(.+?)\\}\\}\", job_text)\n",
    "    tech_stack = tech_stack_match.group(1) if tech_stack_match else \"Not mentioned\"\n",
    "    \n",
    "    # Requirements and skills\n",
    "    requirements = re.findall(r\"(?:Proficient|Strong understanding|Skill|Familiar|Experience)\\b.*\", job_text)\n",
    "    \n",
    "    # Joining extracted info into a single paragraph\n",
    "    responsibilities_str = \" \".join(responsibilities)\n",
    "    requirements_str = \" \".join(requirements)\n",
    "    \n",
    "    # Final summary\n",
    "    summary = (f\"{responsibilities_str} The candidate should have proficiency in {tech_stack}. \"\n",
    "               f\"Additional skills include {requirements_str}.\")\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidential\n",
      "Zanskar Tech Pvt Ltd\n",
      "Frnsup Technologies Pvt. Ltd.\n",
      "Parakh Online\n",
      "Giraf\n",
      "Appening Infotech Pvt. Ltd.\n",
      "Edrevel\n",
      "Decision Management Solutions\n",
      "Comtrek Digital Pvt Ltd\n",
      "Giraf\n",
      "Pristine Technologies\n",
      "Prachas Technologies\n",
      "InScience Healthcare Consulting Pvt. Ltd.\n",
      "SUPERCODER INC\n",
      "Yashaa Digital\n",
      "Uniwise Technology Labs Pvt Ltd\n",
      "Finpoint\n",
      "Emmsons Infotech\n",
      "Zenith Future LLP\n",
      "Collablearn\n",
      "OneModo Technologies Pvt Ltd\n",
      "EPIA\n",
      "Frugal Testing\n"
     ]
    }
   ],
   "source": [
    "# URL of the job listings page\n",
    "job_listings = []\n",
    "with open('job_listings.json') as f:\n",
    "    job_listings = json.load(f)\n",
    "\n",
    "for job in job_listings:\n",
    "    url = job['url']   # Replace with the actual URL\n",
    "    driver.get(url)\n",
    "    time.sleep(10)\n",
    "    \n",
    "    all_data = \"\"  # Initialize all_data to an empty string\n",
    "\n",
    "    try:\n",
    "        # Find the job details container\n",
    "        job_details_container = driver.find_element(By.CLASS_NAME, \"JobDetails_jobDetailsContainer__y9P3L\")\n",
    "\n",
    "        # Find and click the \"Show more\" button\n",
    "        show_more_button = job_details_container.find_element(By.XPATH, \".//*[contains(text(), 'Show more')]\")\n",
    "        show_more_button.click()\n",
    "\n",
    "        # Wait for a moment to ensure the new details are loaded\n",
    "        time.sleep(5)  # You might want to adjust this based on loading times or use WebDriverWait\n",
    "\n",
    "        # Get all the text under that container after clicking \"Show more\"\n",
    "        all_data = job_details_container.text\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        print(f\"Element not found for URL: {url}. Setting job description to empty.\")\n",
    "        # all_data remains an empty string\n",
    "\n",
    "    # Summarize the all_data\n",
    "    # summary = summarize_job_description(all_data)\n",
    "    job['Job_Description'] = all_data\n",
    "    \n",
    "    print(job['Company'])\n",
    "\n",
    "# Save the updated job listings with job descriptions\n",
    "jd_list = []\n",
    "with open('job_listings_with_jd.json') as f:\n",
    "    jd_list = json.load(f)\n",
    "\n",
    "jd_list.append(job_listings)\n",
    "\n",
    "with open('job_listings_with_jd.json', 'w') as json_file:\n",
    "    json.dump(jd_list, json_file, indent=4)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not scrape job description from https://www.glassdoor.co.in/job-listing/andoid-app-developer-intern-constems-ai-JV_IC4477468_KO0,27_KE28,39.htm?jl=1009485312339: Message: Unable to locate element: following-sibling::ul; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n",
      "\n",
      "{'Key Responsibilities': 'Not found', 'Requirements': 'Not found'}\n",
      "Scraped description for Andoid App Developer Intern\n",
      "Could not scrape job description from https://www.glassdoor.co.in/job-listing/backend-developer-intern-international-youth-edu-skills-foundation-JV_IC4477468_KO0,24_KE25,66.htm?jl=1009377074499: Message: Unable to locate element: following-sibling::ul; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n",
      "\n",
      "{'Key Responsibilities': 'Not found', 'Requirements': 'Not found'}\n",
      "Scraped description for Backend Developer Intern\n",
      "Could not scrape job description from https://www.glassdoor.co.in/job-listing/reactjs-developer-intern-constems-ai-JV_IC4477468_KO0,24_KE25,36.htm?jl=1009395932098: Message: Unable to locate element: following-sibling::ul; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n",
      "\n",
      "{'Key Responsibilities': 'Not found', 'Requirements': 'Not found'}\n",
      "Scraped description for ReactJS Developer intern\n"
     ]
    }
   ],
   "source": [
    "def scrape_job_description(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load completely\n",
    "    job_description = {}\n",
    "\n",
    "    try:\n",
    "        # Scrape Key Responsibilities\n",
    "        responsibilities_title = driver.find_element(By.XPATH, \"//*[contains(., 'Responsibilit')]\")\n",
    "        responsibilities_list = responsibilities_title.find_element(By.XPATH, \"following-sibling::ul\").text\n",
    "        job_description['Key Responsibilities'] = responsibilities_list.split(\"\\n\")\n",
    "        \n",
    "        # Scrape Requirements\n",
    "        requirements_title = driver.find_element(By.XPATH, \"//*[contains(., 'Requirement')]\")\n",
    "        requirements_list = requirements_title.find_element(By.XPATH, \"following-sibling::ul\").text\n",
    "        job_description['Requirements'] = requirements_list.split(\"\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not scrape job description from {url}: {e}\")\n",
    "        job_description['Key Responsibilities'] = \"Not found\"\n",
    "        job_description['Requirements'] = \"Not found\"\n",
    "    \n",
    "    print(job_description)\n",
    "    return job_description\n",
    "\n",
    "\n",
    "with open('demo.json') as f:\n",
    "    job_listings = json.load(f)\n",
    "\n",
    "# Loop through each job in the JSON and scrape the job description\n",
    "for job in job_listings:\n",
    "    job_url = job.get(\"Job Link\")\n",
    "    job_details = scrape_job_description(job_url)\n",
    "    job[\"Job Description\"] = job_details\n",
    "    print(f\"Scraped description for {job['Job Title']}\")\n",
    "\n",
    "# Save the updated job listings with descriptions to a new JSON file\n",
    "with open('demo2.json', 'w') as f:\n",
    "    json.dump(job_listings, f, indent=4)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapping from SimplyHired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job listings saved to job_listings.json\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Setup Firefox options\n",
    "firefox_options = webdriver.FirefoxOptions()\n",
    "firefox_options.add_argument(\"--headless\")  # Run in headless mode (without a GUI)\n",
    "firefox_options.add_argument(\"--no-sandbox\")\n",
    "firefox_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Start the WebDriver\n",
    "driver = webdriver.Firefox(service=Service(GeckoDriverManager().install()), options=firefox_options)\n",
    "\n",
    "# URL of the job listings page\n",
    "url = \"https://www.simplyhired.com/search?q=ml+engineer&l=\"  # Replace with the actual URL\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(10)\n",
    "\n",
    "# Locate the job listing elements (updated selector)\n",
    "job_listings = driver.find_elements(By.CSS_SELECTOR, \"[data-testid='searchSerpJob']\")\n",
    "job_data = []\n",
    "count = 0\n",
    "\n",
    "for job in job_listings:\n",
    "    if count > 50:\n",
    "        break\n",
    "    try:\n",
    "        # Extract job title\n",
    "        title_element = job.find_element(By.CSS_SELECTOR, \"[data-testid='searchSerpJobTitle'] a\")\n",
    "        job_title = title_element.text\n",
    "        job_link = title_element.get_attribute(\"href\")\n",
    "        \n",
    "        # Extract employer name\n",
    "        employer_element = job.find_element(By.CSS_SELECTOR, \"[data-testid='companyName']\")\n",
    "        employer_name = employer_element.text\n",
    "        \n",
    "        # Extract location\n",
    "        location_element = job.find_element(By.CSS_SELECTOR, \"[data-testid='searchSerpJobLocation']\")\n",
    "        job_location = location_element.text\n",
    "        \n",
    "        # Extract salary (if available)\n",
    "        try:\n",
    "            salary_element = job.find_element(By.CSS_SELECTOR, \"[data-testid='searchSerpJobSalaryConfirmed']\")\n",
    "            job_salary = salary_element.text\n",
    "        except:\n",
    "            job_salary = \"Not specified\"\n",
    "        \n",
    "        # Maintain the original JSON structure\n",
    "        job_data.append({\n",
    "            \"Position\": job_title,\n",
    "            \"Company\": employer_name,\n",
    "            \"Location\": job_location,\n",
    "            \"Salary\": job_salary,\n",
    "            \"url\": job_link\n",
    "        })\n",
    "        count += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error extracting information:\", e)\n",
    "\n",
    "# Save the data to JSON file\n",
    "with open('job_listings_simplyhired.json', 'w') as json_file:\n",
    "    json.dump(job_data, json_file, indent=4)\n",
    "\n",
    "print(\"Job listings saved to job_listings.json\")\n",
    "print(len(job_listings))\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Firefox options\n",
    "# firefox_options = webdriver.FirefoxOptions()\n",
    "# firefox_options.add_argument(\"--headless\")  # Run in headless mode (without a GUI)\n",
    "# firefox_options.add_argument(\"--no-sandbox\")\n",
    "# firefox_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# # Start the WebDriver\n",
    "# driver = webdriver.Firefox(service=Service(GeckoDriverManager().install()), options=firefox_options)\n",
    "\n",
    "# # URL of the job listings page\n",
    "# job_listings = []\n",
    "# with open('job_listings_simplyhired.json') as f:\n",
    "#     job_listings = json.load(f)\n",
    "\n",
    "# for job in job_listings:\n",
    "#     url = job['url']   # Replace with the actual URL\n",
    "#     driver.get(url)\n",
    "#     time.sleep(10)\n",
    "    \n",
    "#     all_data = \"\"  # Initialize all_data to an empty string\n",
    "\n",
    "#     try:\n",
    "#         # Find the job details container\n",
    "#         job_details_container = driver.find_element(By.CLASS_NAME, \"css-k008qs\")\n",
    "#         time.sleep(5)\n",
    "\n",
    "#         all_data = job_details_container.text\n",
    "\n",
    "#     except NoSuchElementException:\n",
    "#         print(f\"Element not found for URL: {url}. Setting job description to empty.\")\n",
    "#         # all_data remains an empty string\n",
    "\n",
    "#     # Summarize the all_data\n",
    "#     # summary = summarize_job_description(all_data)\n",
    "#     job['Job_Description'] = all_data\n",
    "    \n",
    "#     print(job['Company'])\n",
    "\n",
    "# Save the updated job listings with job descriptions\n",
    "import json\n",
    "jd_list = []\n",
    "with open('job_listings_with_jd.json') as f:\n",
    "    jd_list = json.load(f)\n",
    "    \n",
    "job_listings = []\n",
    "with open('job_listings_with_jd_simplyhired.json') as f:\n",
    "    job_listings = json.load(f)\n",
    "\n",
    "jd_list.append(job_listings)\n",
    "\n",
    "with open('job_listings_with_jd.json', 'w') as json_file:\n",
    "    json.dump(jd_list, json_file, indent=4)\n",
    "\n",
    "# Close the WebDriver\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted job_listings_with_jd.json to data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the JSON file\n",
    "json_file_path = 'job_listings_with_jd.json'\n",
    "data = pd.read_json(json_file_path,orient='records')\n",
    "\n",
    "# Convert to CSV\n",
    "csv_file_path = 'data.csv'\n",
    "data.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Converted {json_file_path} to {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary</th>\n",
       "      <th>url</th>\n",
       "      <th>Job_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ReactJS Developer intern</td>\n",
       "      <td>Constems-AI</td>\n",
       "      <td>Noida</td>\n",
       "      <td>₹10T (Employer Est.)</td>\n",
       "      <td>https://www.glassdoor.co.in/job-listing/reactj...</td>\n",
       "      <td>Constems-AI\\nReactJS Developer intern\\nNoida\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ReactJS Developer Intern</td>\n",
       "      <td>Socialveins Pvt Ltd</td>\n",
       "      <td>Noida</td>\n",
       "      <td>₹3T - ₹5T (Employer Est.)</td>\n",
       "      <td>https://www.glassdoor.co.in/job-listing/reactj...</td>\n",
       "      <td>Socialveins Pvt Ltd\\nReactJS Developer Intern\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Backend Developer Intern</td>\n",
       "      <td>INTERNATIONAL YOUTH EDU-SKILLS FOUNDATION</td>\n",
       "      <td>Noida</td>\n",
       "      <td>₹5T - ₹25T (Employer Est.)</td>\n",
       "      <td>https://www.glassdoor.co.in/job-listing/backen...</td>\n",
       "      <td>INTERNATIONAL YOUTH EDU-SKILLS FOUNDATION\\nBac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andoid App Developer Intern</td>\n",
       "      <td>Constems-AI</td>\n",
       "      <td>Noida</td>\n",
       "      <td>₹10T (Employer Est.)</td>\n",
       "      <td>https://www.glassdoor.co.in/job-listing/andoid...</td>\n",
       "      <td>Constems-AI\\nAndoid App Developer Intern\\nNoid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Java Developer Intern</td>\n",
       "      <td>Parakh Online</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>₹25T - ₹40T (Employer Est.)</td>\n",
       "      <td>https://www.glassdoor.co.in/job-listing/java-d...</td>\n",
       "      <td>Parakh Online\\n4.1\\nJava Developer Intern\\nDel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Data Engineer - Official AI</td>\n",
       "      <td>Pioneer Square Labs</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>https://www.simplyhired.com/job/sv67S1ptv95rHJ...</td>\n",
       "      <td>Data Engineer - Official AI\\nPioneer Square La...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Founding Engineer - Senior Software Engineer (...</td>\n",
       "      <td>G2M Talent</td>\n",
       "      <td>San Francisco Bay Area, CA</td>\n",
       "      <td>$160,000 - $220,000 a year</td>\n",
       "      <td>https://www.simplyhired.com/job/iBtg3UF9aJfCXC...</td>\n",
       "      <td>Founding Engineer - Senior Software Engineer (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Staff Software Engineer, Applied ML</td>\n",
       "      <td>Character.AI</td>\n",
       "      <td>Menlo Park, CA</td>\n",
       "      <td>$150,000 - $250,000 a year</td>\n",
       "      <td>https://www.simplyhired.com/job/KUldZBIxKrHYqZ...</td>\n",
       "      <td>Staff Software Engineer, Applied ML\\nCharacter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2024-01-1E AI/ML Engineer</td>\n",
       "      <td>1st Edge, LLC</td>\n",
       "      <td>Huntsville, AL</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>https://www.simplyhired.com/job/GV1tFzx-nnHeo9...</td>\n",
       "      <td>2024-01-1E AI/ML Engineer\\n1st Edge, LLC\\nHunt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Senior ML Engineer, Embodied AI</td>\n",
       "      <td>Serve Robotics</td>\n",
       "      <td>Remote</td>\n",
       "      <td>$150,000 - $200,000 a year</td>\n",
       "      <td>https://www.simplyhired.com/job/Om1Yc1_l2VCG8J...</td>\n",
       "      <td>Senior ML Engineer, Embodied AI\\nServe Robotic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Position  \\\n",
       "0                            ReactJS Developer intern   \n",
       "1                            ReactJS Developer Intern   \n",
       "2                            Backend Developer Intern   \n",
       "3                         Andoid App Developer Intern   \n",
       "4                               Java Developer Intern   \n",
       "..                                                ...   \n",
       "79                        Data Engineer - Official AI   \n",
       "80  Founding Engineer - Senior Software Engineer (...   \n",
       "81                Staff Software Engineer, Applied ML   \n",
       "82                          2024-01-1E AI/ML Engineer   \n",
       "83                    Senior ML Engineer, Embodied AI   \n",
       "\n",
       "                                      Company                    Location  \\\n",
       "0                                 Constems-AI                       Noida   \n",
       "1                         Socialveins Pvt Ltd                       Noida   \n",
       "2   INTERNATIONAL YOUTH EDU-SKILLS FOUNDATION                       Noida   \n",
       "3                                 Constems-AI                       Noida   \n",
       "4                               Parakh Online                       Delhi   \n",
       "..                                        ...                         ...   \n",
       "79                        Pioneer Square Labs                 Seattle, WA   \n",
       "80                                 G2M Talent  San Francisco Bay Area, CA   \n",
       "81                               Character.AI              Menlo Park, CA   \n",
       "82                              1st Edge, LLC              Huntsville, AL   \n",
       "83                             Serve Robotics                      Remote   \n",
       "\n",
       "                         Salary  \\\n",
       "0          ₹10T (Employer Est.)   \n",
       "1     ₹3T - ₹5T (Employer Est.)   \n",
       "2    ₹5T - ₹25T (Employer Est.)   \n",
       "3          ₹10T (Employer Est.)   \n",
       "4   ₹25T - ₹40T (Employer Est.)   \n",
       "..                          ...   \n",
       "79                Not specified   \n",
       "80   $160,000 - $220,000 a year   \n",
       "81   $150,000 - $250,000 a year   \n",
       "82                Not specified   \n",
       "83   $150,000 - $200,000 a year   \n",
       "\n",
       "                                                  url  \\\n",
       "0   https://www.glassdoor.co.in/job-listing/reactj...   \n",
       "1   https://www.glassdoor.co.in/job-listing/reactj...   \n",
       "2   https://www.glassdoor.co.in/job-listing/backen...   \n",
       "3   https://www.glassdoor.co.in/job-listing/andoid...   \n",
       "4   https://www.glassdoor.co.in/job-listing/java-d...   \n",
       "..                                                ...   \n",
       "79  https://www.simplyhired.com/job/sv67S1ptv95rHJ...   \n",
       "80  https://www.simplyhired.com/job/iBtg3UF9aJfCXC...   \n",
       "81  https://www.simplyhired.com/job/KUldZBIxKrHYqZ...   \n",
       "82  https://www.simplyhired.com/job/GV1tFzx-nnHeo9...   \n",
       "83  https://www.simplyhired.com/job/Om1Yc1_l2VCG8J...   \n",
       "\n",
       "                                      Job_Description  \n",
       "0   Constems-AI\\nReactJS Developer intern\\nNoida\\n...  \n",
       "1   Socialveins Pvt Ltd\\nReactJS Developer Intern\\...  \n",
       "2   INTERNATIONAL YOUTH EDU-SKILLS FOUNDATION\\nBac...  \n",
       "3   Constems-AI\\nAndoid App Developer Intern\\nNoid...  \n",
       "4   Parakh Online\\n4.1\\nJava Developer Intern\\nDel...  \n",
       "..                                                ...  \n",
       "79  Data Engineer - Official AI\\nPioneer Square La...  \n",
       "80  Founding Engineer - Senior Software Engineer (...  \n",
       "81  Staff Software Engineer, Applied ML\\nCharacter...  \n",
       "82  2024-01-1E AI/ML Engineer\\n1st Edge, LLC\\nHunt...  \n",
       "83  Senior ML Engineer, Embodied AI\\nServe Robotic...  \n",
       "\n",
       "[84 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv(\"data.csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
